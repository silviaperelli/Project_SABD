services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    hostname: namenode
    ports:
      - "9870:9870"
      - "8020:8020"
    volumes:
      - namenode_data:/hadoop/dfs/name
      - ./hadoop_init_scripts:/opt/hadoop_init_scripts
      - ./namenode-entrypoint.sh:/custom-entrypoint.sh
      - ./hadoop_conf:/opt/hadoop/etc/hadoop
    entrypoint: /custom-entrypoint.sh
    environment:
      - CLUSTER_NAME=test
    networks:
      - sabd_net

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    hostname: datanode
    volumes:
      - datanode_data:/hadoop/dfs/data
      - ./hadoop_conf:/opt/hadoop/etc/hadoop
    environment:
      - SERVICE_PRECONDITION=namenode:9870
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    depends_on:
      - namenode
    networks:
      - sabd_net

  nifi:
    image: apache/nifi:1.25.0
    container_name: nifi
    restart: always
    ports:
      - "8443:8443"
    volumes:
      - ./nifi_conf/templates:/opt/nifi/nifi-current/conf/templates
      - ./hadoop_conf:/opt/nifi/hadoop_conf
      - nifi_data_conf:/opt/nifi/nifi-current/conf
      - nifi_data_database:/opt/nifi/nifi-current/database_repository
      - nifi_data_flowfile:/opt/nifi/nifi-current/flowfile_repository
      - nifi_data_content:/opt/nifi/nifi-current/content_repository
      - nifi_data_provenance:/opt/nifi/nifi-current/provenance_repository
      - nifi_data_state:/opt/nifi/nifi-current/state
      - nifi_data_logs:/opt/nifi/nifi-current/logs
    environment:
      - NIFI_WEB_HTTPS_PORT=8443
      - NIFI_SENSITIVE_PROPS_KEY= VQHGn0eLMqfDBaElpeZGh3atsh9TwI4s
    depends_on:
      - namenode
      - datanode
    networks:
      - sabd_net
    healthcheck:
      test: ["CMD", "curl", "-f", "-k", "https://localhost:8443/nifi-api/system-diagnostics"]
      interval: 30s
      timeout: 10s
      retries: 5

  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8081:8080"
      - "7077:7077"
    volumes:
      - ./spark_apps:/opt/spark_apps
      - ./hadoop_conf:/opt/bitnami/spark/conf/hadoop:ro
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - HADOOP_CONF_DIR=/opt/bitnami/spark/conf/hadoop
      - LD_PRELOAD=/opt/bitnami/common/lib/libnss_wrapper.so
      - HADOOP_USER_NAME=spark
      - USER=spark
      - LOGNAME=spark
      - HOME=/opt/bitnami/spark
    networks:
      - sabd_net
    depends_on:
      namenode:
        condition: service_healthy
      datanode:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/v1/applications"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  spark-worker-1:
    image: bitnami/spark:3.5
    container_name: spark-worker-1
    hostname: spark-worker-1
    volumes:
      - ./hadoop_conf:/opt/bitnami/spark/conf/hadoop:ro
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=2G
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - HADOOP_CONF_DIR=/opt/bitnami/spark/conf/hadoop
      - SPARK_WORKER_WEBUI_PORT=8082
    depends_on:
      spark-master:
        condition: service_healthy
      namenode:
        condition: service_healthy
    networks:
      - sabd_net
volumes:
  namenode_data:
  datanode_data:
  nifi_data_conf:
  nifi_data_database:
  nifi_data_flowfile:
  nifi_data_content:
  nifi_data_provenance:
  nifi_data_state:
  nifi_data_logs:

networks:
  sabd_net:
    driver: bridge